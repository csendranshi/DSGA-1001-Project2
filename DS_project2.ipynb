{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31667804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a244f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The Life of David Gale (2003)</th>\n",
       "      <th>Wing Commander (1999)</th>\n",
       "      <th>Django Unchained (2012)</th>\n",
       "      <th>Alien (1979)</th>\n",
       "      <th>Indiana Jones and the Last Crusade (1989)</th>\n",
       "      <th>Snatch (2000)</th>\n",
       "      <th>Rambo: First Blood Part II (1985)</th>\n",
       "      <th>Fargo (1996)</th>\n",
       "      <th>Let the Right One In (2008)</th>\n",
       "      <th>Black Swan (2010)</th>\n",
       "      <th>...</th>\n",
       "      <th>When watching a movie I cheer or shout or talk or curse at the screen</th>\n",
       "      <th>When watching a movie I feel like the things on the screen are happening to me</th>\n",
       "      <th>As a movie unfolds I start to have problems keeping track of events that happened earlier</th>\n",
       "      <th>The emotions on the screen \"rub off\" on me - for instance if something sad is happening I get sad or if something frightening is happening I get scared</th>\n",
       "      <th>When watching a movie I get completely immersed in the alternative reality of the film</th>\n",
       "      <th>Movies change my position on social economic or political issues</th>\n",
       "      <th>When watching movies things get so intense that I have to stop watching</th>\n",
       "      <th>Gender identity (1 = female; 2 = male; 3 = self-described)</th>\n",
       "      <th>Are you an only child? (1: Yes; 0: No; -1: Did not respond)</th>\n",
       "      <th>Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.531137</td>\n",
       "      <td>2.464751</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.806495</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.751185</td>\n",
       "      <td>2.634538</td>\n",
       "      <td>2.900757</td>\n",
       "      <td>2.699125</td>\n",
       "      <td>2.906070</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.537720</td>\n",
       "      <td>2.471333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.809467</td>\n",
       "      <td>2.844302</td>\n",
       "      <td>2.754097</td>\n",
       "      <td>2.637355</td>\n",
       "      <td>2.902445</td>\n",
       "      <td>2.701536</td>\n",
       "      <td>2.907452</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.640666</td>\n",
       "      <td>2.574498</td>\n",
       "      <td>3.131971</td>\n",
       "      <td>2.909512</td>\n",
       "      <td>2.943809</td>\n",
       "      <td>2.853692</td>\n",
       "      <td>2.736682</td>\n",
       "      <td>3.000671</td>\n",
       "      <td>2.800051</td>\n",
       "      <td>3.004852</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.476686</td>\n",
       "      <td>2.412456</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.745456</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.691836</td>\n",
       "      <td>2.575730</td>\n",
       "      <td>2.839953</td>\n",
       "      <td>2.640844</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.389385</td>\n",
       "      <td>2.326110</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.657135</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.604037</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.553916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>3.012475</td>\n",
       "      <td>2.997849</td>\n",
       "      <td>3.158353</td>\n",
       "      <td>3.039100</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.050289</td>\n",
       "      <td>2.987122</td>\n",
       "      <td>3.089079</td>\n",
       "      <td>3.025997</td>\n",
       "      <td>3.074744</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.431464</td>\n",
       "      <td>3.312056</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.363354</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>3.007248</td>\n",
       "      <td>2.992744</td>\n",
       "      <td>3.153440</td>\n",
       "      <td>3.034333</td>\n",
       "      <td>3.033142</td>\n",
       "      <td>3.044939</td>\n",
       "      <td>2.981893</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.021248</td>\n",
       "      <td>3.070068</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3.077890</td>\n",
       "      <td>3.062803</td>\n",
       "      <td>3.222826</td>\n",
       "      <td>3.103411</td>\n",
       "      <td>3.101700</td>\n",
       "      <td>3.112978</td>\n",
       "      <td>3.049472</td>\n",
       "      <td>3.151022</td>\n",
       "      <td>3.087521</td>\n",
       "      <td>3.135828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.945150</td>\n",
       "      <td>2.930909</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.972829</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.984129</td>\n",
       "      <td>2.921357</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.960916</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The Life of David Gale (2003)  Wing Commander (1999)  \\\n",
       "0                          2.531137               2.464751   \n",
       "1                          2.537720               2.471333   \n",
       "2                          2.640666               2.574498   \n",
       "3                          2.476686               2.412456   \n",
       "4                          2.389385               2.326110   \n",
       "...                             ...                    ...   \n",
       "1092                       3.012475               2.997849   \n",
       "1093                       3.000000               4.000000   \n",
       "1094                       3.007248               2.992744   \n",
       "1095                       3.077890               3.062803   \n",
       "1096                       2.945150               2.930909   \n",
       "\n",
       "      Django Unchained (2012)  Alien (1979)  \\\n",
       "0                    4.000000      2.806495   \n",
       "1                    1.500000      2.809467   \n",
       "2                    3.131971      2.909512   \n",
       "3                    2.000000      2.745456   \n",
       "4                    3.500000      2.657135   \n",
       "...                       ...           ...   \n",
       "1092                 3.158353      3.039100   \n",
       "1093                 3.431464      3.312056   \n",
       "1094                 3.153440      3.034333   \n",
       "1095                 3.222826      3.103411   \n",
       "1096                 4.000000      2.972829   \n",
       "\n",
       "      Indiana Jones and the Last Crusade (1989)  Snatch (2000)  \\\n",
       "0                                      3.000000       2.751185   \n",
       "1                                      2.844302       2.754097   \n",
       "2                                      2.943809       2.853692   \n",
       "3                                      3.000000       2.691836   \n",
       "4                                      0.500000       2.604037   \n",
       "...                                         ...            ...   \n",
       "1092                                   3.500000       3.050289   \n",
       "1093                                   4.000000       4.000000   \n",
       "1094                                   3.033142       3.044939   \n",
       "1095                                   3.101700       3.112978   \n",
       "1096                                   2.500000       2.984129   \n",
       "\n",
       "      Rambo: First Blood Part II (1985)  Fargo (1996)  \\\n",
       "0                              2.634538      2.900757   \n",
       "1                              2.637355      2.902445   \n",
       "2                              2.736682      3.000671   \n",
       "3                              2.575730      2.839953   \n",
       "4                              0.500000      1.000000   \n",
       "...                                 ...           ...   \n",
       "1092                           2.987122      3.089079   \n",
       "1093                           2.500000      3.363354   \n",
       "1094                           2.981893      3.500000   \n",
       "1095                           3.049472      3.151022   \n",
       "1096                           2.921357      3.000000   \n",
       "\n",
       "      Let the Right One In (2008)  Black Swan (2010)  ...  \\\n",
       "0                        2.699125           2.906070  ...   \n",
       "1                        2.701536           2.907452  ...   \n",
       "2                        2.800051           3.004852  ...   \n",
       "3                        2.640844           4.000000  ...   \n",
       "4                        2.553916           0.000000  ...   \n",
       "...                           ...                ...  ...   \n",
       "1092                     3.025997           3.074744  ...   \n",
       "1093                     3.500000           3.500000  ...   \n",
       "1094                     3.021248           3.070068  ...   \n",
       "1095                     3.087521           3.135828  ...   \n",
       "1096                     2.960916           3.500000  ...   \n",
       "\n",
       "      When watching a movie I cheer or shout or talk or curse at the screen  \\\n",
       "0                                                   1.0                       \n",
       "1                                                   3.0                       \n",
       "2                                                   5.0                       \n",
       "3                                                   3.0                       \n",
       "4                                                   2.0                       \n",
       "...                                                 ...                       \n",
       "1092                                                3.0                       \n",
       "1093                                                5.0                       \n",
       "1094                                                6.0                       \n",
       "1095                                                1.0                       \n",
       "1096                                                3.0                       \n",
       "\n",
       "      When watching a movie I feel like the things on the screen are happening to me  \\\n",
       "0                                                   6.0                                \n",
       "1                                                   1.0                                \n",
       "2                                                   4.0                                \n",
       "3                                                   1.0                                \n",
       "4                                                   3.0                                \n",
       "...                                                 ...                                \n",
       "1092                                                4.0                                \n",
       "1093                                                3.0                                \n",
       "1094                                                3.0                                \n",
       "1095                                                1.0                                \n",
       "1096                                                4.0                                \n",
       "\n",
       "      As a movie unfolds I start to have problems keeping track of events that happened earlier  \\\n",
       "0                                                   2.0                                           \n",
       "1                                                   1.0                                           \n",
       "2                                                   3.0                                           \n",
       "3                                                   1.0                                           \n",
       "4                                                   2.0                                           \n",
       "...                                                 ...                                           \n",
       "1092                                                3.0                                           \n",
       "1093                                                5.0                                           \n",
       "1094                                                1.0                                           \n",
       "1095                                                1.0                                           \n",
       "1096                                                1.0                                           \n",
       "\n",
       "      The emotions on the screen \"rub off\" on me - for instance if something sad is happening I get sad or if something frightening is happening I get scared  \\\n",
       "0                                                   5.0                                                                                                         \n",
       "1                                                   6.0                                                                                                         \n",
       "2                                                   5.0                                                                                                         \n",
       "3                                                   4.0                                                                                                         \n",
       "4                                                   5.0                                                                                                         \n",
       "...                                                 ...                                                                                                         \n",
       "1092                                                5.0                                                                                                         \n",
       "1093                                                5.0                                                                                                         \n",
       "1094                                                6.0                                                                                                         \n",
       "1095                                                4.0                                                                                                         \n",
       "1096                                                4.0                                                                                                         \n",
       "\n",
       "      When watching a movie I get completely immersed in the alternative reality of the film  \\\n",
       "0                                                   5.0                                        \n",
       "1                                                   5.0                                        \n",
       "2                                                   5.0                                        \n",
       "3                                                   5.0                                        \n",
       "4                                                   6.0                                        \n",
       "...                                                 ...                                        \n",
       "1092                                                5.0                                        \n",
       "1093                                                5.0                                        \n",
       "1094                                                6.0                                        \n",
       "1095                                                3.0                                        \n",
       "1096                                                4.0                                        \n",
       "\n",
       "      Movies change my position on social economic or political issues  \\\n",
       "0                                                   5.0                  \n",
       "1                                                   3.0                  \n",
       "2                                                   4.0                  \n",
       "3                                                   3.0                  \n",
       "4                                                   4.0                  \n",
       "...                                                 ...                  \n",
       "1092                                                4.0                  \n",
       "1093                                                6.0                  \n",
       "1094                                                4.0                  \n",
       "1095                                                3.0                  \n",
       "1096                                                4.0                  \n",
       "\n",
       "      When watching movies things get so intense that I have to stop watching  \\\n",
       "0                                                   1.0                         \n",
       "1                                                   2.0                         \n",
       "2                                                   4.0                         \n",
       "3                                                   1.0                         \n",
       "4                                                   4.0                         \n",
       "...                                                 ...                         \n",
       "1092                                                4.0                         \n",
       "1093                                                5.0                         \n",
       "1094                                                2.0                         \n",
       "1095                                                1.0                         \n",
       "1096                                                1.0                         \n",
       "\n",
       "      Gender identity (1 = female; 2 = male; 3 = self-described)  \\\n",
       "0                                                   1.0            \n",
       "1                                                   1.0            \n",
       "2                                                   1.0            \n",
       "3                                                   1.0            \n",
       "4                                                   1.0            \n",
       "...                                                 ...            \n",
       "1092                                                1.0            \n",
       "1093                                                1.0            \n",
       "1094                                                1.0            \n",
       "1095                                                1.0            \n",
       "1096                                                1.0            \n",
       "\n",
       "      Are you an only child? (1: Yes; 0: No; -1: Did not respond)  \\\n",
       "0                                                     0             \n",
       "1                                                     0             \n",
       "2                                                     1             \n",
       "3                                                     0             \n",
       "4                                                     1             \n",
       "...                                                 ...             \n",
       "1092                                                  0             \n",
       "1093                                                  0             \n",
       "1094                                                  0             \n",
       "1095                                                  0             \n",
       "1096                                                  0             \n",
       "\n",
       "      Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)  \n",
       "0                                                     1                   \n",
       "1                                                     0                   \n",
       "2                                                     0                   \n",
       "3                                                     1                   \n",
       "4                                                     1                   \n",
       "...                                                 ...                   \n",
       "1092                                                  0                   \n",
       "1093                                                  0                   \n",
       "1094                                                  0                   \n",
       "1095                                                  1                   \n",
       "1096                                                  1                   \n",
       "\n",
       "[1097 rows x 477 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_cleaned.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83c03589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['I enjoy driving fast', 'I enjoy rollercoasters ',\n",
       "       'Have you ever bungee-jumped?', 'I enjoy impulse shopping',\n",
       "       'I sometimes go out on weeknights even if I have work to do',\n",
       "       'I enjoy doing things without too much planning ',\n",
       "       'Have you ever been rock climbing?',\n",
       "       'I enjoy being in large loud crowds like the Times Square Ball Drop on New Years Eve',\n",
       "       'I enjoy going to large music or dance festivals ',\n",
       "       'I enjoy watching horror movies', 'No risk - No fun',\n",
       "       'I like to be surprised even if it startles or scares me',\n",
       "       'Have you ever parachuted?', 'I enjoy haunted houses',\n",
       "       'I had a sheltered upbringing', 'My life is very stressful',\n",
       "       'I value my life to be well ordered and predictable',\n",
       "       'Have you ridden a motorcycle?', 'Have you gambled or bet for money?',\n",
       "       'Have you ever been sky-diving?', 'Is talkative',\n",
       "       'Tends to find fault with others', 'Does a thorough job',\n",
       "       'Is depressed/Blue', 'Is original/comes up with new ideas',\n",
       "       'Is reserved', 'Is helpful and unselfish with others',\n",
       "       'Can be somewhat careless', 'Is relaxed/handles stress well',\n",
       "       'Is curious about many different things', 'Is full of energy',\n",
       "       'Starts quarrels with others', 'Is a reliable worker', 'Can be tense',\n",
       "       'Is ingenious/a deep thinker', 'Generates a lot of Enthusiasm',\n",
       "       'Has a forgiving nature', 'Tends to be disorganized', 'Worries a lot',\n",
       "       'Has an active imagination', 'Tends to be quiet',\n",
       "       'Is generally trusting', 'Tends to be lazy',\n",
       "       'Is emotionally stable/not easily upset', 'is inventive',\n",
       "       'Has an assertive personality', 'Can be cold and aloof',\n",
       "       'Perseveres until the task is finished', 'Can be moody',\n",
       "       'Values artistic/aesthetic experiences', 'Is sometimes shy/inhibited',\n",
       "       'Is considerate and kind to almost everyone', 'Does things efficiently',\n",
       "       'Remains calm in tense situations', 'Prefers work that is routine',\n",
       "       'is outgoing/sociable', 'Is sometimes rude to others',\n",
       "       'Makes plans and follows through with them', 'Gets nervous easily',\n",
       "       'Likes to reflect/play with ideas', 'Has few artistic interests',\n",
       "       'Likes to cooperate with others', 'Is easily distracted',\n",
       "       'Is sophisticated in art or music or literature',\n",
       "       'I have cried during a movie',\n",
       "       'I have trouble following the story of a movie',\n",
       "       'I have trouble remembering the story of a movie a couple of days after seeing it',\n",
       "       'When watching a movie I cheer or shout or talk or curse at the screen',\n",
       "       'When watching a movie I feel like the things on the screen are happening to me',\n",
       "       'As a movie unfolds I start to have problems keeping track of events that happened earlier',\n",
       "       'The emotions on the screen \"rub off\" on me - for instance if something sad is happening I get sad or if something frightening is happening I get scared',\n",
       "       'When watching a movie I get completely immersed in the alternative reality of the film',\n",
       "       'Movies change my position on social economic or political issues',\n",
       "       'When watching movies things get so intense that I have to stop watching',\n",
       "       'Gender identity (1 = female; 2 = male; 3 = self-described)',\n",
       "       'Are you an only child? (1: Yes; 0: No; -1: Did not respond)',\n",
       "       'Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[401:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "359bebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={'index': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161db08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['The Life of David Gale (2003)', 'Wing Commander (1999)',\n",
       "       'Django Unchained (2012)', 'Alien (1979)',\n",
       "       'Indiana Jones and the Last Crusade (1989)', 'Snatch (2000)',\n",
       "       'Rambo: First Blood Part II (1985)', 'Fargo (1996)',\n",
       "       'Let the Right One In (2008)', 'Black Swan (2010)',\n",
       "       ...\n",
       "       'X-Men 2 (2003)', 'The Usual Suspects (1995)', 'The Mask (1994)',\n",
       "       'Jaws (1975)', 'Harry Potter and the Chamber of Secrets (2002)',\n",
       "       'Patton (1970)', 'Anaconda (1997)', 'Twister (1996)',\n",
       "       'MacArthur (1977)', 'Look Who's Talking (1989)'],\n",
       "      dtype='object', length=400)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:400].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37a05c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                                                                    1093.000000\n",
       "The Life of David Gale (2003)                                                 3.000000\n",
       "Wing Commander (1999)                                                         4.000000\n",
       "Django Unchained (2012)                                                       3.431464\n",
       "Alien (1979)                                                                  3.312056\n",
       "                                                                              ...     \n",
       "Movies change my position on social economic or political issues              6.000000\n",
       "When watching movies things get so intense that I have to stop watching       5.000000\n",
       "Gender identity (1 = female; 2 = male; 3 = self-described)                    1.000000\n",
       "Are you an only child? (1: Yes; 0: No; -1: Did not respond)                   0.000000\n",
       "Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)            0.000000\n",
       "Name: 1093, Length: 478, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1093]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ddff1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The Life of David Gale (2003)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.531137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.537720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.640666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.476686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.389385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>3.012475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>3.007248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3.077890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.945150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      The Life of David Gale (2003)\n",
       "0                          2.531137\n",
       "1                          2.537720\n",
       "2                          2.640666\n",
       "3                          2.476686\n",
       "4                          2.389385\n",
       "...                             ...\n",
       "1092                       3.012475\n",
       "1093                       3.000000\n",
       "1094                       3.007248\n",
       "1095                       3.077890\n",
       "1096                       2.945150\n",
       "\n",
       "[1097 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['The Life of David Gale (2003)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938f63e",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afcaa4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Movie ID             Best Predictor       COD\n",
      "208                I.Q. (1994)     Erik the Viking (1989)  0.672159\n",
      "203     Erik the Viking (1989)                I.Q. (1994)  0.672159\n",
      "287  The Straight Story (1999)               Congo (1995)  0.663001\n",
      "282               Congo (1995)  The Straight Story (1999)  0.663001\n",
      "377         The Lookout (2007)              Patton (1970)  0.645374\n",
      "395              Patton (1970)         The Lookout (2007)  0.645374\n",
      "300                 Ran (1985)       Heavy Traffic (1973)  0.641827\n",
      "309       Heavy Traffic (1973)                 Ran (1985)  0.641827\n",
      "369   The Station Agent (2003)             Ed Wood (1994)  0.637398\n",
      "326             Ed Wood (1994)   The Station Agent (2003)  0.637398\n",
      "                           Movie ID  \\\n",
      "80                    Avatar (2009)   \n",
      "95              Interstellar (2014)   \n",
      "319               La La Land (2016)   \n",
      "9                 Black Swan (2010)   \n",
      "190   The Cabin in the Woods (2012)   \n",
      "248              Grown Ups 2 (2013)   \n",
      "55                  Clueless (1995)   \n",
      "357  The Wolf of Wall Street (2013)   \n",
      "30        Planet of the Apes (2001)   \n",
      "117           Shutter Island (2010)   \n",
      "\n",
      "                                        Best Predictor       COD  \n",
      "80   Pirates of the Caribbean: Dead Man's Chest (2006)  0.064908  \n",
      "95                                       Torque (2004)  0.070179  \n",
      "319                                 The Lookout (2007)  0.080699  \n",
      "9                   Once Upon a Time in America (1984)  0.080994  \n",
      "190                 The Texas Chainsaw Massacre (1974)  0.098913  \n",
      "248                              Knight and Day (2010)  0.100224  \n",
      "55                           Back to the Future (1985)  0.103506  \n",
      "357                                   Inception (2010)  0.113149  \n",
      "30                                  Equilibrium (2002)  0.113271  \n",
      "117                         Requiem for a Dream (2000)  0.113327  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns: 'movie_id', 'user_id', 'rating'\n",
    "\n",
    "# Placeholder for storing COD values\n",
    "cod_values = []\n",
    "\n",
    "# Placeholder for storing the best predictor for each movie\n",
    "best_predictors = []\n",
    "\n",
    "# Iterate over each movie\n",
    "for movie in df.columns[1:401].unique():\n",
    "    # Select data for the current movie\n",
    "    current_movie_data = df[[movie]]\n",
    "\n",
    "    # Placeholder for storing COD values for the current movie\n",
    "    movie_cod_values = []\n",
    "\n",
    "    # Placeholder for storing best predictor for the current movie\n",
    "    best_predictor = None\n",
    "    best_cod = 0\n",
    "\n",
    "    # Iterate over all other movies to build 399 models\n",
    "    for other_movie in df.columns[1:401].unique():\n",
    "        if other_movie != movie:\n",
    "            # Select data for the other movie\n",
    "            other_movie_data = df[[other_movie]]\n",
    "\n",
    "            # Extract X and y\n",
    "            X = other_movie_data\n",
    "            y = current_movie_data\n",
    "\n",
    "            # Fit a linear regression model\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "\n",
    "            # Predict ratings\n",
    "            predictions = model.predict(X)\n",
    "\n",
    "            # Calculate COD\n",
    "            cod = r2_score(y, predictions)\n",
    "\n",
    "            # Check if this model is the best predictor\n",
    "            if cod > best_cod:\n",
    "                best_cod = cod\n",
    "                best_predictor = other_movie\n",
    "\n",
    "            movie_cod_values.append(cod)\n",
    "\n",
    "    # Calculate the average COD for the current movie\n",
    "    avg_cod = sum(movie_cod_values) / len(movie_cod_values)\n",
    "    cod_values.append(avg_cod)\n",
    "\n",
    "    # Store the best predictor for the current movie\n",
    "    best_predictors.append((movie, best_predictor, best_cod))\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(cod_values, bins=20, edgecolor='black')\n",
    "plt.xlabel('Coefficient of Determination (COD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of COD Values')\n",
    "plt.show()\n",
    "\n",
    "# Display the table of best and worst predictors\n",
    "best_predictors_df = pd.DataFrame(best_predictors, columns=['Movie ID', 'Best Predictor', 'COD'])\n",
    "print(best_predictors_df.sort_values(by='COD', ascending=False).head(10))\n",
    "print(best_predictors_df.sort_values(by='COD').head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8a4f5",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Now we'll be focusing on the top and bottom 10 movies and using mutliple regression to analyse further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a908001",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10 = best_predictors_df.sort_values(by='COD').head(10)\n",
    "top_10 = best_predictors_df.sort_values(by='COD', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23886ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Avatar (2009)', 'Interstellar (2014)', 'La La Land (2016)',\n",
       "       'Black Swan (2010)', 'The Cabin in the Woods (2012)',\n",
       "       'Grown Ups 2 (2013)', 'Clueless (1995)',\n",
       "       'The Wolf of Wall Street (2013)', 'Planet of the Apes (2001)',\n",
       "       'Shutter Island (2010)'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_10['Movie ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c542b9f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m     50\u001b[0m X_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X, X_additional], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Predict ratings\u001b[39;00m\n\u001b[1;32m     54\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_combined)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns: 'movie_id', 'user_id', 'rating', and additional predictors\n",
    "\n",
    "# Placeholder for storing COD values\n",
    "cod_values = []\n",
    "\n",
    "# Placeholder for storing R^2 values for the new multiple regression models\n",
    "r2_values = []\n",
    "\n",
    "# Placeholder for storing the best predictor for each movie\n",
    "best_predictors = []\n",
    "\n",
    "# Iterate over each movie\n",
    "for movie in bottom_10['Movie ID'].unique():\n",
    "    # Select data for the current movie\n",
    "    current_movie_data = df[movie]\n",
    "\n",
    "    # Placeholder for storing COD values for the current movie\n",
    "    movie_cod_values = []\n",
    "\n",
    "    # Placeholder for storing R^2 values for the new multiple regression models\n",
    "    movie_r2_values = []\n",
    "\n",
    "    # Placeholder for storing best predictor for the current movie\n",
    "    best_predictor = None\n",
    "    best_cod = 0\n",
    "\n",
    "    # Iterate over all other movies to build 399 models\n",
    "    for other_movie in bottom_10['Movie ID'].unique():\n",
    "        if other_movie != movie:\n",
    "            # Select data for the other movie\n",
    "            other_movie_data = df[other_movie]\n",
    "\n",
    "#             # Merge the two datasets on 'user_id'\n",
    "#             merged_data = pd.merge(current_movie_data, other_movie_data, on='user_id', suffixes=('_current', '_other'))\n",
    "\n",
    "            # Extract additional predictors\n",
    "            X_additional = df[['Gender identity (1 = female; 2 = male; 3 = self-described)', 'Are you an only child? (1: Yes; 0: No; -1: Did not respond)', 'Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)']]\n",
    "            \n",
    "            # Extract X and y\n",
    "            X = other_movie_data\n",
    "            y = current_movie_data\n",
    "\n",
    "            # Fit a multiple regression model\n",
    "            model = LinearRegression()\n",
    "            X_combined = pd.concat([X, X_additional], axis=1)\n",
    "            model.fit(X_combined, y)\n",
    "\n",
    "            # Predict ratings\n",
    "            predictions = model.predict(X_combined)\n",
    "\n",
    "            # Calculate R^2\n",
    "            r2 = r2_score(y, predictions)\n",
    "\n",
    "            # Check if this model is the best predictor\n",
    "            if r2 > best_cod:\n",
    "                best_cod = r2\n",
    "                best_predictor = other_movie\n",
    "\n",
    "            movie_r2_values.append(r2)\n",
    "            movie_cod_values.append(cod)\n",
    "\n",
    "    # Calculate the average COD for the current movie\n",
    "    avg_cod = sum(movie_cod_values) / len(movie_cod_values)\n",
    "    cod_values.append(avg_cod)\n",
    "\n",
    "    # Calculate the average R^2 for the new multiple regression models\n",
    "    avg_r2 = sum(movie_r2_values) / len(movie_r2_values)\n",
    "    r2_values.append(avg_r2)\n",
    "\n",
    "    # Store the best predictor for the current movie\n",
    "    best_predictors.append((movie_id, best_predictor, best_cod))\n",
    "\n",
    "# Plot scatterplot\n",
    "plt.scatter(cod_values, r2_values, alpha=0.5)\n",
    "plt.xlabel('Coefficient of Determination (COD)')\n",
    "plt.ylabel('R^2 for Multiple Regression Models')\n",
    "plt.title('Scatterplot of COD vs R^2')\n",
    "plt.show()\n",
    "\n",
    "# Display the table of best and worst predictors\n",
    "best_predictors_df = pd.DataFrame(best_predictors, columns=['Movie ID', 'Best Predictor', 'R^2'])\n",
    "\n",
    "print(best_predictors_df.sort_values(by='R^2', ascending=False).head(10))\n",
    "print(best_predictors_df.sort_values(by='R^2').head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d03f0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_predictors = df[['Gender identity (1 = female; 2 = male; 3 = self-described)', 'Are you an only child? (1: Yes; 0: No; -1: Did not respond)', 'Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41ff1697",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Fit a multiple regression model\u001b[39;00m\n\u001b[1;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Predict ratings\u001b[39;00m\n\u001b[1;32m     42\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns: 'movie_id', 'user_id', 'rating', 'gender_identity', 'sibship_status', 'social_viewing_preferences'\n",
    "\n",
    "# Placeholder for storing old COD values\n",
    "old_cod_values = []\n",
    "\n",
    "# Placeholder for storing new R² values\n",
    "new_r2_values = []\n",
    "\n",
    "# Placeholder for storing information about the models\n",
    "model_info = []\n",
    "\n",
    "# Iterate over the best and least well-predicted movies\n",
    "for _, row in best_predictors_df.sort_values(by='COD').head(10).iterrows():\n",
    "    movie_id = row['Movie ID']\n",
    "    best_predictor = row['Best Predictor']\n",
    "\n",
    "    # Select data for the current movie\n",
    "    current_movie_data = df[movie_id]\n",
    "\n",
    "    # Select data for the best predictor movie\n",
    "    best_predictor_data = df[best_predictor]\n",
    "\n",
    "    # Merge the two datasets on 'user_id'\n",
    "    merged_data_ = pd.merge(current_movie_data, best_predictor_data,left_index=True, right_index=True, suffixes=('_current', '_other'))\n",
    "    merged_data = pd.merge(merged_data_, additional_predictors,left_index=True, right_index=True)\n",
    "\n",
    "    # Extract X and y\n",
    "    X = df[['Gender identity (1 = female; 2 = male; 3 = self-described)', 'Are you an only child? (1: Yes; 0: No; -1: Did not respond)', 'Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)']]\n",
    "    y = merged_data[movie_id]\n",
    "\n",
    "    # Fit a multiple regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict ratings\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # Calculate R²\n",
    "    r2 = r2_score(y, predictions)\n",
    "\n",
    "    # Store information about the model\n",
    "    model_info.append({'Movie ID': movie_id, 'Best Predictor': best_predictor, 'R²': r2})\n",
    "\n",
    "    # Store old COD value\n",
    "    old_cod_values.append(row['COD'])\n",
    "\n",
    "    # Store new R² value\n",
    "    new_r2_values.append(r2)\n",
    "\n",
    "# Create a scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=old_cod_values, y=new_r2_values)\n",
    "plt.xlabel('Old COD (Simple Linear Regression)')\n",
    "plt.ylabel('New R² (Multiple Regression)')\n",
    "plt.title('Comparison of Old COD and New R²')\n",
    "plt.show()\n",
    "\n",
    "# Display information about the models\n",
    "model_info_df = pd.DataFrame(model_info)\n",
    "print(model_info_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24b8b7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avatar (2009)</th>\n",
       "      <th>Pirates of the Caribbean: Dead Man's Chest (2006)</th>\n",
       "      <th>Gender identity (1 = female; 2 = male; 3 = self-described)</th>\n",
       "      <th>Are you an only child? (1: Yes; 0: No; -1: Did not respond)</th>\n",
       "      <th>Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.783891</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.989225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.031207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.939510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1097 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avatar (2009)  Pirates of the Caribbean: Dead Man's Chest (2006)  \\\n",
       "0          3.500000                                           0.500000   \n",
       "1          1.500000                                           1.500000   \n",
       "2          3.000000                                           3.000000   \n",
       "3          2.783891                                           2.000000   \n",
       "4          3.500000                                           2.000000   \n",
       "...             ...                                                ...   \n",
       "1092       3.000000                                           2.989225   \n",
       "1093       4.000000                                           3.500000   \n",
       "1094       4.000000                                           2.500000   \n",
       "1095       3.000000                                           3.031207   \n",
       "1096       2.500000                                           2.939510   \n",
       "\n",
       "      Gender identity (1 = female; 2 = male; 3 = self-described)  \\\n",
       "0                                                   1.0            \n",
       "1                                                   1.0            \n",
       "2                                                   1.0            \n",
       "3                                                   1.0            \n",
       "4                                                   1.0            \n",
       "...                                                 ...            \n",
       "1092                                                1.0            \n",
       "1093                                                1.0            \n",
       "1094                                                1.0            \n",
       "1095                                                1.0            \n",
       "1096                                                1.0            \n",
       "\n",
       "      Are you an only child? (1: Yes; 0: No; -1: Did not respond)  \\\n",
       "0                                                     0             \n",
       "1                                                     0             \n",
       "2                                                     1             \n",
       "3                                                     0             \n",
       "4                                                     1             \n",
       "...                                                 ...             \n",
       "1092                                                  0             \n",
       "1093                                                  0             \n",
       "1094                                                  0             \n",
       "1095                                                  0             \n",
       "1096                                                  0             \n",
       "\n",
       "      Movies are best enjoyed alone (1: Yes; 0: No; -1: Did not respond)  \n",
       "0                                                     1                   \n",
       "1                                                     0                   \n",
       "2                                                     0                   \n",
       "3                                                     1                   \n",
       "4                                                     1                   \n",
       "...                                                 ...                   \n",
       "1092                                                  0                   \n",
       "1093                                                  0                   \n",
       "1094                                                  0                   \n",
       "1095                                                  1                   \n",
       "1096                                                  1                   \n",
       "\n",
       "[1097 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "457e2cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.500000\n",
       "1       1.500000\n",
       "2       3.000000\n",
       "3       2.000000\n",
       "4       2.000000\n",
       "          ...   \n",
       "1092    2.989225\n",
       "1093    3.500000\n",
       "1094    2.500000\n",
       "1095    3.031207\n",
       "1096    2.939510\n",
       "Name: Pirates of the Caribbean: Dead Man's Chest (2006), Length: 1097, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " best_predictor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f905882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
